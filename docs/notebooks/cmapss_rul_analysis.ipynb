{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-MAPSS Turbofan RUL Analysis with PRISM\n",
    "\n",
    "NASA's Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) dataset for Remaining Useful Life (RUL) prediction.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "| Dataset | Operating Conditions | Fault Modes | Train Engines | Test Engines |\n",
    "|---------|---------------------|-------------|---------------|---------------|\n",
    "| FD001 | 1 (Sea Level) | 1 (HPC Degradation) | 100 | 100 |\n",
    "| FD002 | 6 (Various) | 1 (HPC Degradation) | 260 | 259 |\n",
    "| FD003 | 1 (Sea Level) | 2 (HPC + Fan) | 100 | 100 |\n",
    "| FD004 | 6 (Various) | 2 (HPC + Fan) | 249 | 248 |\n",
    "\n",
    "## Sensors (21)\n",
    "\n",
    "| Sensor | Description | Unit |\n",
    "|--------|-------------|------|\n",
    "| T2 | Fan inlet temperature | 째R |\n",
    "| T24 | LPC outlet temperature | 째R |\n",
    "| T30 | HPC outlet temperature | 째R |\n",
    "| T50 | LPT outlet temperature | 째R |\n",
    "| P2 | Fan inlet pressure | psia |\n",
    "| P15 | Bypass duct pressure | psia |\n",
    "| P30 | HPC outlet pressure | psia |\n",
    "| Nf | Physical fan speed | rpm |\n",
    "| Nc | Physical core speed | rpm |\n",
    "| epr | Engine pressure ratio | - |\n",
    "| Ps30 | HPC outlet static pressure | psia |\n",
    "| phi | Fuel flow / Ps30 | - |\n",
    "| NRf | Corrected fan speed | rpm |\n",
    "| NRc | Corrected core speed | rpm |\n",
    "| BPR | Bypass ratio | - |\n",
    "| farB | Burner fuel-air ratio | - |\n",
    "| htBleed | Bleed enthalpy | - |\n",
    "| Nf_dmd | Demanded fan speed | rpm |\n",
    "| PCNfR_dmd | Demanded corrected fan speed | rpm |\n",
    "| W31 | HPT coolant bleed | lbm/s |\n",
    "| W32 | LPT coolant bleed | lbm/s |\n",
    "\n",
    "## PRISM Approach\n",
    "\n",
    "Use Laplace field geometry to detect regime changes that precede failure:\n",
    "- **Divergence spikes** = energy injection (degradation onset)\n",
    "- **Gradient magnitude** = rate of change acceleration\n",
    "- **Normalized field** = anomaly detection relative to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "\n",
    "DOMAIN = 'cmapss'\n",
    "DATA_DIR = Path(f'/Users/jasonrudder/prism-mac/data/{DOMAIN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw observations\n",
    "obs = pl.read_parquet(DATA_DIR / 'raw' / 'observations.parquet')\n",
    "meta = pl.read_parquet(DATA_DIR / 'raw' / 'engine_metadata.parquet')\n",
    "signals = pl.read_parquet(DATA_DIR / 'raw' / 'signals.parquet')\n",
    "\n",
    "print(f\"Total observations: {len(obs):,}\")\n",
    "print(f\"Total signals: {obs['signal_id'].n_unique():,}\")\n",
    "print(f\"Total engines: {len(meta):,}\")\n",
    "print()\n",
    "print(\"Dataset summary:\")\n",
    "print(meta.group_by('dataset').agg([\n",
    "    pl.len().alias('engines'),\n",
    "    pl.col('total_cycles').mean().alias('avg_cycles'),\n",
    "    pl.col('total_cycles').max().alias('max_cycles'),\n",
    "]).sort('dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample engine trajectory (FD001, unit 1)\n",
    "sample_unit = obs.filter(pl.col('signal_id').str.contains('FD001_0001_'))\n",
    "\n",
    "# Pivot to wide format\n",
    "sample_wide = sample_unit.pivot(\n",
    "    on='signal_id',\n",
    "    index='obs_date',\n",
    "    values='value'\n",
    ").sort('obs_date')\n",
    "\n",
    "print(f\"Sample engine FD001_0001: {len(sample_wide)} cycles\")\n",
    "print(f\"Sensors available: {len(sample_wide.columns) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample engine sensor trajectories\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "sensors = ['FD001_0001_T30', 'FD001_0001_P30', 'FD001_0001_Nf', \n",
    "           'FD001_0001_phi', 'FD001_0001_NRc', 'FD001_0001_RUL']\n",
    "\n",
    "for ax, sensor in zip(axes.flat, sensors):\n",
    "    if sensor in sample_wide.columns:\n",
    "        y = sample_wide[sensor].to_numpy()\n",
    "        ax.plot(y, linewidth=0.8)\n",
    "        ax.set_title(sensor.split('_')[-1])\n",
    "        ax.set_xlabel('Cycle')\n",
    "\n",
    "plt.suptitle('FD001 Unit 1: Sensor Trajectories to Failure', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RUL Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine lifetimes by dataset\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "for ax, dataset in zip(axes, ['FD001', 'FD002', 'FD003', 'FD004']):\n",
    "    cycles = meta.filter(pl.col('dataset') == dataset)['total_cycles'].to_numpy()\n",
    "    ax.hist(cycles, bins=30, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "    ax.axvline(np.mean(cycles), color='red', linestyle='--', label=f'Mean: {np.mean(cycles):.0f}')\n",
    "    ax.set_title(f'{dataset}')\n",
    "    ax.set_xlabel('Cycles to Failure')\n",
    "    ax.legend()\n",
    "\n",
    "axes[0].set_ylabel('Count')\n",
    "plt.suptitle('Engine Lifetime Distribution by Dataset', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run PRISM Pipeline\n",
    "\n",
    "Execute in terminal:\n",
    "```bash\n",
    "# Compute behavioral vectors with normalization\n",
    "python -m prism.entry_points.signal_vector --signal --domain cmapss --testing\n",
    "\n",
    "# Compute Laplace field (raw)\n",
    "python -m prism.entry_points.laplace --level signal --domain cmapss --value-col metric_value\n",
    "\n",
    "# Compute Laplace field (normalized)\n",
    "python -m prism.entry_points.laplace --level signal --domain cmapss --value-col metric_value_norm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if PRISM outputs exist\n",
    "from prism.db.parquet_store import get_parquet_path\n",
    "\n",
    "vector_path = get_parquet_path('vector', 'signal', domain=DOMAIN)\n",
    "field_path = get_parquet_path('vector', 'signal_field', domain=DOMAIN)\n",
    "field_norm_path = get_parquet_path('vector', 'signal_field_norm', domain=DOMAIN)\n",
    "\n",
    "print(f\"Vector exists: {vector_path.exists()}\")\n",
    "print(f\"Field (raw) exists: {field_path.exists()}\")\n",
    "print(f\"Field (norm) exists: {field_norm_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Laplace Field Analysis (After PRISM Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PRISM outputs (run this after pipeline completes)\n",
    "try:\n",
    "    vectors = pl.read_parquet(vector_path)\n",
    "    field_raw = pl.read_parquet(field_path)\n",
    "    field_norm = pl.read_parquet(field_norm_path)\n",
    "    \n",
    "    print(f\"Vector rows: {len(vectors):,}\")\n",
    "    print(f\"Field (raw) rows: {len(field_raw):,}\")\n",
    "    print(f\"Field (norm) rows: {len(field_norm):,}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"PRISM outputs not found. Run the pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze divergence patterns vs RUL\n",
    "try:\n",
    "    # Get RUL signals\n",
    "    rul_field = field_norm.filter(pl.col('signal_id').str.contains('_RUL'))\n",
    "    \n",
    "    # Sample: correlate divergence with RUL\n",
    "    print(\"RUL field statistics:\")\n",
    "    print(f\"  Divergence mean: {rul_field['divergence'].mean():.4f}\")\n",
    "    print(f\"  Divergence std: {rul_field['divergence'].std():.4f}\")\n",
    "except:\n",
    "    print(\"Run PRISM pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Early Warning Detection\n",
    "\n",
    "Key hypothesis: Divergence spikes in normalized Laplace field should precede failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for post-analysis\n",
    "# After running PRISM, analyze:\n",
    "# 1. Divergence vs RUL correlation\n",
    "# 2. Detection lag (how many cycles before failure does divergence spike)\n",
    "# 3. False positive rate at different thresholds\n",
    "\n",
    "print(\"Analysis pending PRISM pipeline completion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Data Loaded\n",
    "- **5.8M observations** across 4 datasets\n",
    "- **31,152 signals** (21 sensors + RUL per engine)\n",
    "- **1,416 engines** total (709 train + 707 test)\n",
    "\n",
    "### Next Steps\n",
    "1. Run `signal_vector` to compute behavioral metrics\n",
    "2. Run `laplace` on both raw and normalized values\n",
    "3. Analyze divergence patterns vs RUL\n",
    "4. Build early warning threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
